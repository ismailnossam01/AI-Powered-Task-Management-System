{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdDk478G5Tsf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv(\"task_data_200.csv\")\n",
        "\n",
        "# Preview\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic stats\n",
        "print(df.info())\n",
        "print(df['Priority'].value_counts())\n",
        "print(df['Completed'].value_counts())\n",
        "print(df['Assigned_To'].value_counts().head(10))\n",
        "\n",
        "# Plot: Priority distribution\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Priority', data=df, palette='viridis')\n",
        "plt.title(\"Priority Distribution\")\n",
        "plt.show()\n",
        "\n",
        "# Plot: Completed status\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.countplot(x='Completed', data=df, palette='coolwarm')\n",
        "plt.title(\"Completed vs Not Completed\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "uxbfyG9G8vfF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "import string\n",
        "\n",
        "# Clean text\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = ''.join([char for char in text if char not in string.punctuation])\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    return ' '.join([word for word in text.split() if word not in stop_words])\n",
        "\n",
        "df['Clean_Description'] = df['Description'].apply(clean_text)\n",
        "\n",
        "# TF-IDF\n",
        "tfidf = TfidfVectorizer()\n",
        "X = tfidf.fit_transform(df['Clean_Description'])\n",
        "y = df['Priority']\n",
        "\n",
        "# Train/test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train model\n",
        "model = MultinomialNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate\n",
        "print(classification_report(y_test, y_pred))\n",
        "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "qH5x1hbL8vjI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train_rf, X_test_rf, y_train_rf, y_test_rf = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_rf, y_train_rf)\n",
        "\n",
        "# Predictions\n",
        "y_pred_rf = rf.predict(X_test_rf)\n",
        "\n",
        "# Evaluation Report\n",
        "print(\"Classification Report (Random Forest):\\n\")\n",
        "print(classification_report(y_test_rf, y_pred_rf))\n",
        "\n",
        "# Confusion Matrix\n",
        "plt.figure(figsize=(6,4))\n",
        "sns.heatmap(confusion_matrix(y_test_rf, y_pred_rf), annot=True, fmt='d', cmap='Greens')\n",
        "plt.title(\" Random Forest - Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "H_taKutb8vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "\n",
        "# Convert Deadline to datetime\n",
        "df['Deadline'] = pd.to_datetime(df['Deadline'])\n",
        "\n",
        "# Add Days_Left\n",
        "df['Days_Left'] = (df['Deadline'] - pd.Timestamp.today()).dt.days\n",
        "\n",
        "# Binary: Urgent if Days_Left < 5\n",
        "df['Urgent'] = df['Days_Left'] < 5\n",
        "\n",
        "# Convert Completed to binary\n",
        "df['Completed_Binary'] = df['Completed'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Check updated columns\n",
        "df[['Description', 'Priority', 'Days_Left', 'Urgent', 'Completed_Binary']].head()\n"
      ],
      "metadata": {
        "id": "x6J8BixE8vri"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from scipy.sparse import hstack\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. TF-IDF on Cleaned Descriptions\n",
        "tfidf = TfidfVectorizer()\n",
        "X_text = tfidf.fit_transform(df['Clean_Description'])\n",
        "\n",
        "# 2. Additional features\n",
        "X_meta = df[['Days_Left', 'Urgent', 'Completed_Binary']].copy()\n",
        "scaler = StandardScaler()\n",
        "X_meta_scaled = scaler.fit_transform(X_meta)\n",
        "\n",
        "# 3. Combine TF-IDF + Meta\n",
        "X_combined = hstack([X_text, X_meta_scaled])\n",
        "\n",
        "# 4. Labels\n",
        "y_combined = df['Priority']\n",
        "\n",
        "# 5. Split\n",
        "X_train_cb, X_test_cb, y_train_cb, y_test_cb = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)\n",
        "\n",
        "# 6. Model\n",
        "rf_combined = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_combined.fit(X_train_cb, y_train_cb)\n",
        "\n",
        "# 7. Predict & Evaluate\n",
        "y_pred_cb = rf_combined.predict(X_test_cb)\n",
        "print(\"Combined Model Evaluation:\\n\")\n",
        "print(classification_report(y_test_cb, y_pred_cb))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test_cb, y_pred_cb), annot=True, fmt='d', cmap='Blues')\n",
        "plt.title(\"Confusion Matrix - Combined Model\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "okrKeCx5AGM8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# New Voting Classifier without Naive Bayes\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model_rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "model_lr = LogisticRegression(max_iter=1000)\n",
        "\n",
        "voting_clf = VotingClassifier(estimators=[\n",
        "    ('rf', model_rf),\n",
        "    ('lr', model_lr)\n",
        "], voting='hard')\n",
        "\n",
        "# Train and evaluate\n",
        "voting_clf.fit(X_train_v, y_train_v)\n",
        "y_pred_v = voting_clf.predict(X_test_v)\n",
        "\n",
        "print(\"VotingClassifier (RF + LR) Results:\\n\")\n",
        "print(classification_report(y_test_v, y_pred_v))\n",
        "\n",
        "sns.heatmap(confusion_matrix(y_test_v, y_pred_v), annot=True, fmt='d', cmap='YlGnBu')\n",
        "plt.title(\"Confusion Matrix - VotingClassifier (RF + LR)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "gXNu8AoZAGP5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import random\n",
        "\n",
        "# Create a copy for assignment\n",
        "df_assignment = df.copy()\n",
        "\n",
        "# Get team members list (you can customize)\n",
        "team_members = [\"Kiran\", \"Sneha\", \"Rohit\", \"Aanya\"]\n",
        "\n",
        "# Initialize workload dictionary\n",
        "workload = {member: 0 for member in team_members}\n",
        "\n",
        "# Shuffle rows to randomize assignment\n",
        "df_assignment = df_assignment.sample(frac=1, random_state=42)\n",
        "\n",
        "# Assign tasks based on priority (High > Medium > Low)\n",
        "priority_order = ['High', 'Medium', 'Low']\n",
        "assigned_tasks = []\n",
        "\n",
        "for priority in priority_order:\n",
        "    tasks = df_assignment[df_assignment['Priority'] == priority]\n",
        "    for idx, row in tasks.iterrows():\n",
        "        # Find member with least load\n",
        "        assignee = min(workload, key=workload.get)\n",
        "        workload[assignee] += 1\n",
        "        df_assignment.at[idx, 'Assigned_To'] = assignee\n",
        "        assigned_tasks.append((row['Task_ID'], assignee, priority))\n",
        "\n",
        "# View result\n",
        "print(\"Task Assignment Complete!\\nWorkload per Member:\")\n",
        "for member, count in workload.items():\n",
        "    print(f\"{member}: {count} tasks\")\n",
        "\n",
        "# Preview assigned DataFrame\n",
        "df_assignment[['Task_ID', 'Description', 'Priority', 'Assigned_To']].head(10)\n"
      ],
      "metadata": {
        "id": "Io1HwhulAGT8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}